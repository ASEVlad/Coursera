{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tensorflow2.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "83n3dCM6VN7P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEPclKAiVu63",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(train_images[42])\n",
        "print(train_labels[42])\n",
        "print(train_images[42])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UH4mbAOWtTr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_images  = train_images / 255.0\n",
        "test_images = test_images / 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBXj-TfLRpyK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    keras.layers.Dense(64,activation=tf.nn.relu),\n",
        "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzxLNK5FVEg7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "4e36d30d-8f46-426a-a7e8-8bb59cb6dc82"
      },
      "source": [
        "model.compile(optimizer = tf.train.AdamOptimizer(),\n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_images, train_labels, epochs=5)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 4s 64us/step - loss: 0.5192 - acc: 0.8202\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.3894 - acc: 0.8617\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.3507 - acc: 0.8734\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.3264 - acc: 0.8818\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.3108 - acc: 0.8866\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fcf6b8efdd8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImsP_SleVbLK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "8b514c48-2a30-46b6-c392-9fb871c19909"
      },
      "source": [
        "model.evaluate(test_images, test_labels)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 0s 42us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3880143308162689, 0.8608]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUJrgSGPW9zE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYQjP9coa0QO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Gl4yI-aa07T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjGtAXRrZn25",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('loss')<0.4):\n",
        "      print('\\nLossis low so cancelling training')\n",
        "      self.model.stop_training = True\n",
        "callbacks = myCallback()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-Cqb_SIZn5h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wp2qkn2WZn74",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_images  = train_images / 255.0\n",
        "test_images = test_images / 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6ao01RZZn-h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    keras.layers.Dense(64,activation=tf.nn.relu),\n",
        "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zN1NnQMZoBD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "1999b4d2-e8df-4475-8dbb-732a8c8a203f"
      },
      "source": [
        "model.compile(optimizer = 'adam',\n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_images, train_labels, epochs=10, callbacks=[callbacks])"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 5s 80us/step - loss: 0.5201 - acc: 0.8180\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.3916 - acc: 0.8598\n",
            "\n",
            "Lossis low so cancelling training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fcf68814da0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-T-gnUSkZoDf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "c47c7db3-cf96-4fd5-bf46-af73a29f49d7"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('acc')>0.85):\n",
        "      print(\"\\nReached 60% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "callbacks = myCallback()\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, epochs=10, callbacks=[callbacks])"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 15s 243us/sample - loss: 0.4764 - acc: 0.8293\n",
            "Epoch 2/10\n",
            "59840/60000 [============================>.] - ETA: 0s - loss: 0.3574 - acc: 0.8692\n",
            "Reached 60% accuracy so cancelling training!\n",
            "60000/60000 [==============================] - 15s 247us/sample - loss: 0.3576 - acc: 0.8692\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fcf677039b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z49oro8BZoGU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nm3fV8urd2w7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "outputId": "291b48ee-2c15-4766-ddcb-46c09be4c9fd"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if (logs.get('acc')>0.99):\n",
        "      print('\\nReached 99% accuracy so cancelling training!')\n",
        "      self.model.stop_training = True\n",
        "\n",
        "callback = myCallback()\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train/255.0\n",
        "x_test = x_test/255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(28,28)),\n",
        "    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, epochs=10, callbacks=[callback])"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 15s 248us/sample - loss: 0.1971 - acc: 0.9414\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 14s 241us/sample - loss: 0.0794 - acc: 0.9758\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 14s 241us/sample - loss: 0.0523 - acc: 0.9837\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 15s 251us/sample - loss: 0.0373 - acc: 0.9879\n",
            "Epoch 5/10\n",
            "59808/60000 [============================>.] - ETA: 0s - loss: 0.0282 - acc: 0.9907\n",
            "Reached 99% accuracy so cancelling training!\n",
            "60000/60000 [==============================] - 15s 247us/sample - loss: 0.0283 - acc: 0.9907\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fcf67252630>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkAcHpGDd2tB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2775
        },
        "outputId": "4a9c0e23-ee5b-446e-b25b-87c72ef7c31b"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(x_train[42])\n",
        "print(y_train[42])\n",
        "print(x_train[42])"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7\n",
            "[[0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.00392157 0.10196078 0.43529412 0.76470588 0.90196078\n",
            "  0.11764706 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.10980392\n",
            "  0.41960784 0.76470588 0.99607843 0.99607843 0.99607843 0.95686275\n",
            "  0.07843137 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.18039216 0.65490196 0.97254902\n",
            "  0.99607843 0.87058824 0.57254902 0.58823529 0.99607843 0.68235294\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.25490196 0.8745098  0.96470588 0.99607843 0.6\n",
            "  0.23921569 0.03921569 0.         0.18823529 0.99607843 0.50588235\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.33333333 0.68627451 0.64313725 0.31372549 0.00784314\n",
            "  0.         0.         0.         0.18823529 0.99607843 0.47058824\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.71372549 0.99607843 0.0627451\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.81176471 0.99607843 0.0627451\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.81176471 0.79215686 0.01176471\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.10980392 0.97254902 0.66666667 0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.41960784 0.99607843 0.23921569 0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.65098039 0.98823529 0.11764706 0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.74901961 0.80784314 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.74901961 0.80784314 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.05490196 0.96470588 0.72941176 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.35686275 0.99607843 0.30196078 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.68627451 0.99607843 0.18823529 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.68627451 0.94117647 0.10588235 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.84313725 0.87058824 0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.45098039 1.         0.59607843 0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.5254902  1.         0.26666667 0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAADNlJREFUeJzt3X+MHPV5x/H3g2Ns6oSAIXUdQCUx\nTiqEFBOdIFVIGkoTAUU1aRWEW1FHQjhVQCpS/giif5S2/1hREoSqFskUCxOlJJEIwn+gNsRqg1JF\nlIO6/IjTGMgh7BgMISokFOMfT/+4dXSB27ljd3ZnzfN+SaednWfm5tHIn5vZ/a73G5mJpHqO67oB\nSd0w/FJRhl8qyvBLRRl+qSjDLxVl+KWiDL9UlOGXinrHOA92fCzL5awY5yGlUl7jl7yeB2Ix2w4V\n/oi4GLgFWAL8U2Zubtp+OSs4Py4a5pCSGjyYOxa97cC3/RGxBPgH4BLgbGBDRJw96O+TNF7DvOY/\nD3gyM5/OzNeBbwDr22lL0qgNE/7TgGfnPN/TW/drImJTRExHxPRBDgxxOEltGvm7/Zm5JTOnMnNq\nKctGfThJizRM+PcCZ8x5fnpvnaRjwDDhfwhYGxHvi4jjgSuB7e20JWnUBh7qy8xDEXEd8K/MDvVt\nzcwnWutM0kgNNc6fmfcB97XUi6Qx8uO9UlGGXyrK8EtFGX6pKMMvFWX4paIMv1SU4ZeKMvxSUYZf\nKsrwS0UZfqkowy8VZfilogy/VJThl4oy/FJRhl8qyvBLRRl+qSjDLxVl+KWiDL9UlOGXijL8UlGG\nXyrK8EtFGX6pKMMvFTXULL0RMQO8AhwGDmXmVBtNSRq9ocLfc2FmvtjC75E0Rt72S0UNG/4EvhMR\nD0fEpjYakjQew972X5CZeyPiN4H7I+JHmfnA3A16fxQ2ASznN4Y8nKS2DHXlz8y9vcf9wD3AefNs\nsyUzpzJzainLhjmcpBYNHP6IWBER7zq6DHwKeLytxiSN1jC3/auAeyLi6O/558z8l1a6kjRyA4c/\nM58GPtRiL5LGyKE+qSjDLxVl+KWiDL9UlOGXijL8UlFt/K8+HctmP6fR15I1ZzbWf/JnqxvrH//D\n/+pb23DKg437fumyP2msH961u7GuZl75paIMv1SU4ZeKMvxSUYZfKsrwS0UZfqkox/nfBpZ8YE3f\n2sxnVjXu+7H1/cfhAf7xtLsH6mkx9h1+tbEerzTXNRyv/FJRhl8qyvBLRRl+qSjDLxVl+KWiDL9U\nlOP8E+DIBesa6y99sXm8+7vr7uhbO/G45Y373v3Lkxvra++/prEe7zjSWP/xhbf3rf3prqsa9z1h\nz08a6xqOV36pKMMvFWX4paIMv1SU4ZeKMvxSUYZfKmrBcf6I2ApcBuzPzHN661YC3wTOBGaAKzLz\n56Nrc7K9+sfnN9av33xXY/1jJ/xHY/2U405orP/O9z7ft/beu45v3HfF937UWF/78sON9SO/d25j\nnQv7l/buav6ugbNwnH+UFnPlvwO4+A3rbgB2ZOZaYEfvuaRjyILhz8wHgJfesHo9sK23vA24vOW+\nJI3YoK/5V2Xmvt7yc0Dz/ZukiTP0G36ZmUD2q0fEpoiYjojpgxwY9nCSWjJo+J+PiNUAvcf9/TbM\nzC2ZOZWZU0tZNuDhJLVt0PBvBzb2ljcC97bTjqRxWTD8EXEX8APggxGxJyKuBjYDn4yI3cAf9J5L\nOoYsOM6fmRv6lC5quZdj1qunNv8N/fuZ32+s/+2rzeP4x997UmP9/dv+s3/xyOHGfZuro7Xktejw\n6PITflJRhl8qyvBLRRl+qSjDLxVl+KWi/OruFpy65QfNG2xpLv9We62M3bK/eW7gfc+6+anGepfD\nkBV45ZeKMvxSUYZfKsrwS0UZfqkowy8VZfilohzn11A+stKv1z5WeeWXijL8UlGGXyrK8EtFGX6p\nKMMvFWX4paIc59dI3bj/w31rR372xvlfNU5e+aWiDL9UlOGXijL8UlGGXyrK8EtFGX6pqAXH+SNi\nK3AZsD8zz+mtuwm4Bniht9mNmXnfqJpUd5Z8YE1j/dqTv9ZYv+SxP+9be/ehJwfqSe1YzJX/DuDi\nedbfnJnrej8GXzrGLBj+zHwA8KNY0tvMMK/5r4uIRyNia0Sc3FpHksZi0PDfCqwB1gH7gK/02zAi\nNkXEdERMH+TAgIeT1LaBwp+Zz2fm4cw8AtwGnNew7ZbMnMrMqaUsG7RPSS0bKPwRsXrO008Dj7fT\njqRxWcxQ313AJ4BTI2IP8NfAJyJiHZDADPC5EfYoaQQWDH9mbphn9e0j6EUTaOYzqxrrJx63vLG+\n7NaVbbajFvkJP6kowy8VZfilogy/VJThl4oy/FJRfnW3Gi0//2eN9UMcbqyvePLnfWvNe2rUvPJL\nRRl+qSjDLxVl+KWiDL9UlOGXijL8UlGO86vROe/Z11jf/OKHGuuHd+1usx21yCu/VJThl4oy/FJR\nhl8qyvBLRRl+qSjDLxVl+KWiDL9UlOGXijL8UlGGXyrK8EtFGX6pKMMvFbXg/+ePiDOAO4FVQAJb\nMvOWiFgJfBM4E5gBrsjM/l/Srom05NRTGutfPn17Y/3zM+sXOMKLb7EjjctirvyHgC9k5tnAR4Br\nI+Js4AZgR2auBXb0nks6RiwY/szcl5mP9JZfAXYBpwHrgW29zbYBl4+qSUnte0uv+SPiTOBc4EFg\nVWYe/Y6n55h9WSDpGLHo8EfEO4G7gesz8+W5tcxMZt8PmG+/TRExHRHTBzkwVLOS2rOo8EfEUmaD\n//XM/HZv9fMRsbpXXw3sn2/fzNySmVOZObWUZW30LKkFC4Y/IgK4HdiVmV+dU9oObOwtbwTubb89\nSaOymK/u/ihwFfBYROzsrbsR2Ax8KyKuBp4BrhhNixqlfVd+sLF+ynEnNNafvW1tY/0kh/om1oLh\nz8zvA9GnfFG77UgaFz/hJxVl+KWiDL9UlOGXijL8UlGGXyrKKbqLe/cf/XSo/U985rWWOtG4eeWX\nijL8UlGGXyrK8EtFGX6pKMMvFWX4paIc51ejpw79X2N96U//t7F+uM1m1Cqv/FJRhl8qyvBLRRl+\nqSjDLxVl+KWiDL9UlOP8xV15+kON9Z0H3ttYP7z76Tbb0Rh55ZeKMvxSUYZfKsrwS0UZfqkowy8V\nZfilohYc54+IM4A7gVVAAlsy85aIuAm4Bniht+mNmXnfqBrVYGb+7ncb639x0q2N9bP+/bON9TXs\nfKstaUIs5kM+h4AvZOYjEfEu4OGIuL9Xuzkzvzy69iSNyoLhz8x9wL7e8isRsQs4bdSNSRqtt/Sa\nPyLOBM4FHuytui4iHo2IrRFxcp99NkXEdERMH+TAUM1Kas+iwx8R7wTuBq7PzJeBW4E1wDpm7wy+\nMt9+mbklM6cyc2opy1poWVIbFhX+iFjKbPC/npnfBsjM5zPzcGYeAW4Dzhtdm5LatmD4IyKA24Fd\nmfnVOetXz9ns08Dj7bcnaVQW827/R4GrgMci4ui4zo3AhohYx+zw3wzwuZF0qKEcXHlkqP1X3eNL\ntberxbzb/30g5ik5pi8dw/yEn1SU4ZeKMvxSUYZfKsrwS0UZfqmoyMyxHezEWJnnx0VjO55UzYO5\ng5fzpfmG5t/EK79UlOGXijL8UlGGXyrK8EtFGX6pKMMvFTXWcf6IeAF4Zs6qU4EXx9bAWzOpvU1q\nX2Bvg2qzt9/OzPcsZsOxhv9NB4+YzsypzhpoMKm9TWpfYG+D6qo3b/ulogy/VFTX4d/S8fGbTGpv\nk9oX2NugOumt09f8krrT9ZVfUkc6CX9EXBwR/xMRT0bEDV300E9EzETEYxGxMyKmO+5la0Tsj4jH\n56xbGRH3R8Tu3uO806R11NtNEbG3d+52RsSlHfV2RkT8W0T8MCKeiIi/7K3v9Nw19NXJeRv7bX9E\nLAF+DHwS2AM8BGzIzB+OtZE+ImIGmMrMzseEI+LjwC+AOzPznN66LwEvZebm3h/OkzPzixPS203A\nL7qeubk3oczquTNLA5cDn6XDc9fQ1xV0cN66uPKfBzyZmU9n5uvAN4D1HfQx8TLzAeClN6xeD2zr\nLW9j9h/P2PXpbSJk5r7MfKS3/ApwdGbpTs9dQ1+d6CL8pwHPznm+h8ma8juB70TEwxGxqetm5rGq\nN206wHPAqi6bmceCMzeP0xtmlp6YczfIjNdt8w2/N7sgMz8MXAJc27u9nUg5+5ptkoZrFjVz87jM\nM7P0r3R57gad8bptXYR/L3DGnOen99ZNhMzc23vcD9zD5M0+/PzRSVJ7j/s77udXJmnm5vlmlmYC\nzt0kzXjdRfgfAtZGxPsi4njgSmB7B328SUSs6L0RQ0SsAD7F5M0+vB3Y2FveCNzbYS+/ZlJmbu43\nszQdn7uJm/E6M8f+A1zK7Dv+TwF/1UUPffp6P/DfvZ8nuu4NuIvZ28CDzL43cjVwCrAD2A18F1g5\nQb19DXgMeJTZoK3uqLcLmL2lfxTY2fu5tOtz19BXJ+fNT/hJRfmGn1SU4ZeKMvxSUYZfKsrwS0UZ\nfqkowy8VZfilov4fX13mmVodIccAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejjwCkbJd2pb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPWXLtCYd2mE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpSBtVmed2iz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7AKaBXvd2fU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUxBwLyFd2We",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}